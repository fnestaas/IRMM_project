{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report on Adversarial Examples\n",
    "This notebook should \n",
    "1. Train new models with different parameters\n",
    "1. for each model, generate an **untargeted** PGD attack\n",
    "1. Plot the results\n",
    "\n",
    "Read these notes before running stuff :) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import subprocess\n",
    "from pathlib import Path \n",
    "from matplotlib import pyplot as plt \n",
    "import json \n",
    "import optuna \n",
    "from model_utils import find_best_model, choose_model\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "prefix = 'experimentation/'\n",
    "adv_dir = 'attacks/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities for reporting accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stats(dir):\n",
    "    with open(dir) as f:\n",
    "        stats = json.load(f)\n",
    "    return stats \n",
    "\n",
    "def get_stats_regular(which=1, duration=100, model='max', root=prefix, dir=None):\n",
    "    \"\"\" \n",
    "    Load stats of model specified directly using the directory of the model, or using which, duration and model name ('max' for latest)\n",
    "    \"\"\"\n",
    "    if dir is None:\n",
    "        dir = Path(root) / f'{which=}_{duration=}'\n",
    "    model = choose_model(dir, model)\n",
    "    dir = Path(model)\n",
    "    return load_stats(dir / 'stats.json') \n",
    "\n",
    "def get_stats_attack(which=1, duration=100, model='max', root=prefix, adv_dir=adv_dir, dir=None, attacks=['targeted', 'targeted_increase', 'targeted_decrease', 'untargeted']):\n",
    "    \"\"\" \n",
    "    Load adversarial stats of model specified directly using the directory of the model, \n",
    "    or using which, duration and model name ('max' for latest).\n",
    "    Returns a dict of dicts, where the outer dict has attack types as keys and the inner uses perturbation sizes\n",
    "    \"\"\"\n",
    "    if dir is None:\n",
    "        # dir is not specified so we find it based on other information\n",
    "        dir = Path(root) / f'{which=}_{duration=}'\n",
    "        model = choose_model(dir, model)\n",
    "        dir = model / adv_dir \n",
    "    # create a dict of dicts based on attack type and perturbation size\n",
    "    retval = {}\n",
    "    for p in dir.iterdir():\n",
    "        key = str(p).split('/')[-1]\n",
    "        perturbation_size = key.split('=')[-1]\n",
    "        for attack in attacks:\n",
    "            if f\"attack_type='{attack}'\" in key: \n",
    "                if not attack in retval.keys():\n",
    "                    retval[attack] = {}\n",
    "                try:\n",
    "                    retval[attack][perturbation_size] = load_stats(p / 'adv_stats.json')\n",
    "                except FileNotFoundError:\n",
    "                    retval[attack][perturbation_size] = {'acc': np.nan, 'cm': np.zeros((3, 3))}\n",
    "\n",
    "    return retval"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train New Models\n",
    "Each with a specific set of parameters, including data parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_args(param):\n",
    "    \"\"\"\n",
    "    turn parameter dictionary into list of arguments\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for k, v in param.items():\n",
    "        out.append('--' + k)\n",
    "        out.append(str(v))\n",
    "    return out \n",
    "\n",
    "durations = [10, 20, 50]\n",
    "whichs = [1, 3]\n",
    "n_epochs = 30\n",
    "hs = 64 \n",
    "dropout = 1/3\n",
    "num_layers = 2\n",
    "thresholds = [.1, .15, .25, .35]\n",
    "n_classes = len(thresholds) + 1\n",
    "opt_time_seconds = 10*60\n",
    "model_params = {\n",
    "    f'{prefix}{which=}_{duration=}': {\n",
    "        'duration': duration, 'which': which, 'n_classes': n_classes, 'n_epochs': n_epochs,\n",
    "        'dropout': dropout, 'hs': hs, 'num_layers': num_layers, 'thresholds': thresholds\n",
    "    } \n",
    "    for duration in durations for which in whichs\n",
    "}\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ATTENTION\n",
    "The code below takes time to run and should only be run if you want to make your own model. It is not necessary for the majority of this notebook, since the results are already on github. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create models\n",
    "for name, v in model_params.items():\n",
    "    which = v['which']\n",
    "    duration = v['duration']\n",
    "    def objective(trial):\n",
    "        v['dropout'] = trial.suggest_float('dropout', 0, .5)\n",
    "        v['num_layers'] = trial.suggest_int('num_layers', 1, 4)\n",
    "        v['hs'] = trial.suggest_int('hs', 64, 256, log=True)\n",
    "        print('\\n\\n', v, '\\n\\n')\n",
    "        subprocess.run(['python', 'lstm.py'] + make_args(v) + ['--target_directory', name]) \n",
    "        acc = get_stats_regular(which=which, duration=duration)['acc']\n",
    "        return -acc # maximize acc\n",
    "\n",
    "    study = optuna.create_study()\n",
    "    study.enqueue_trial({'dropout': dropout, 'num_layers': num_layers, 'hs': hs})\n",
    "    study.optimize(objective, timeout=opt_time_seconds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save (sequential) model predictions on regular test data\n",
    "### ATTENTION:\n",
    "Again, you don't have to run this if you downloaded the results already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, v in model_params.items():\n",
    "    which = v['which']\n",
    "    duration = v['duration']\n",
    "    model_path = choose_model(Path(f'{prefix}/{which=}_{duration=}'), 'best') \n",
    "    subprocess.call(['python', 'test_sequential.py', '--model_path', model_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # find the best accuracy in the directories\n",
    "# best_accs = {}\n",
    "# for name, v in model_params.items():\n",
    "#     best_accs[name] = find_best_model(name)\n",
    "# print(*[v[1] for v in best_accs.values()], sep='\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Adversarial Examples\n",
    "Save the results with the model in the appropriate folder, both for targeted and untargeted attacks. \n",
    "\n",
    "Parameters of the attack:\n",
    "- Attack type\n",
    "- Perturbation size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the case of breaking the process, it is nice to know the order of the scripts executed\n",
    "# Generate that order\n",
    "order = []\n",
    "attack_types = ['untargeted'] # ['targeted_increase', 'targeted_decrease', 'targeted', 'untargeted']\n",
    "perturbation_sizes = [.1*i for i in range(6)]\n",
    "for name in model_params.keys():\n",
    "    attack_params = {\n",
    "        f'{adv_dir}{attack_type=}_{perturbation_size=}/': {'attack_type': attack_type, 'perturbation_size': perturbation_size} \n",
    "        for attack_type in attack_types for perturbation_size in perturbation_sizes\n",
    "    }\n",
    "    order.extend([(name, attack_name) for attack_name in attack_params.keys()])\n",
    "\n",
    "def later_experiment(comp, ref, order=order):\n",
    "    \"\"\"\n",
    "    Check if comp is later than ref in order\n",
    "    \"\"\"\n",
    "    if ref == None:\n",
    "        return True\n",
    "    if ref =='skip_all':\n",
    "        return False \n",
    "    j = len(order)\n",
    "    for i, o in enumerate(order):\n",
    "        if str(o[0]) == str(comp[0]) and str(o[1]) == str(comp[1]):\n",
    "            j = i \n",
    "            break \n",
    "    for o in order[:j+1]:\n",
    "        if str(o[0]) == str(ref[0]) and str(o[1]) == str(ref[1]):\n",
    "            return True \n",
    "    return False "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ATTENTION:\n",
    "Again, you don't have to run this if you downloaded the results already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each model, make a number of attacks \n",
    "# To that end, make a subfolder \"attacks\" for each of the models\n",
    "\n",
    "# ref = (f'{prefix}/which=4_duration=150', \"attacks/attack_type='targeted'_perturbation_size=0.01/\") \n",
    "ref = None\n",
    "# ref = 'skip_all'\n",
    "\n",
    "for name in model_params.keys():\n",
    "    attack_params = {\n",
    "        f'{adv_dir}{attack_type=}_{perturbation_size=}/': {'attack_type': attack_type, 'perturbation_size': perturbation_size} \n",
    "        for attack_type in attack_types for perturbation_size in perturbation_sizes\n",
    "    }\n",
    "    for attack_name, v in attack_params.items():\n",
    "        if later_experiment((name, attack_name), ref):\n",
    "            print('doing', (name, attack_name))\n",
    "            if 'increase' in name:\n",
    "                preference = 'increase'\n",
    "            elif 'decrease' in name:\n",
    "                preference = 'decrease'\n",
    "            else:\n",
    "                preference = 'None'\n",
    "            subprocess.run(['python', 'attack.py'] + make_args(v) + ['--source_directory', name, '--target_directory', attack_name, '--model_name', 'best', '--preference', preference, '--validation_data', 'False'])\n",
    "        else:\n",
    "            print('skipped', (name, attack_name))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_to_duration_mapping = {0: 0., 1: .125, 2: .2, 3: .3, 4: .7}\n",
    "\n",
    "def pred_to_cycles(y, idx, data_metadata):\n",
    "    thresholds = data_metadata['thresholds']\n",
    "    if idx >= len(y): return np.nan # the model did not recommend to switch\n",
    "    predicted_class = int(y[idx])\n",
    "    max_life = thresholds[-1] * 3\n",
    "    if predicted_class == n_classes - 1:\n",
    "        if int(y[-1]) == n_classes - 1:\n",
    "            return ((len(y) - idx - 1) * 10 + thresholds[-1]) / max_life\n",
    "            # return np.nan # cannot say what the actual remaining life is\n",
    "        else:\n",
    "            for i, v in enumerate(y):\n",
    "                if v < n_classes - 1:\n",
    "                    break \n",
    "            return ((i - idx) * 10 + (thresholds[-2] + thresholds[-1]) / 2) / max_life \n",
    "    if predicted_class == 0: return 0. \n",
    "    return (thresholds[predicted_class] + thresholds[predicted_class - 1]) /2 / max_life\n",
    "\n",
    "def cost_of_matrix(cm, critical_class, c_over=15.1, c_under=40):\n",
    "    \"\"\" \n",
    "    Compute the cost according to the relevant confusion matrix\n",
    "    \"\"\"\n",
    "    cm = np.array(cm)\n",
    "    # find the number of cases where we predict a non-critical class when it is in fact critical\n",
    "    n_underestimate = np.sum(cm[critical_class+1:, :critical_class]) # predicted class is critical_class + 1 or higher\n",
    "    # find the number of non-critical cases which are predicted as critical\n",
    "    n_overestimate = np.sum(cm[:critical_class, critical_class+1:])\n",
    "    return (n_underestimate * c_under + n_overestimate * c_over) / np.sum(cm)\n",
    "\n",
    "def num_cycles_left(preds, ys, rule, data_metadata):\n",
    "    stop = rule(preds) # last sample to include \n",
    "    return pred_to_cycles(ys, stop, data_metadata)\n",
    "\n",
    "def load_p_y(model_path, errors=None):\n",
    "    with open(Path(model_path) / 'preds_ys.json') as f:\n",
    "        preds_ys = json.load(f)\n",
    "    preds = preds_ys['preds']\n",
    "    ys = preds_ys['ys']\n",
    "    if errors is not None:\n",
    "        for engine, t, error in errors:\n",
    "            preds[engine][t] = error\n",
    "    return preds, ys \n",
    "\n",
    "def mean_num_cycles_left(model_path, rule, errors, data_metadata):\n",
    "    preds, ys = load_p_y(model_path, errors)\n",
    "    res = np.zeros((len(preds), ))\n",
    "    for i, (p, y) in enumerate(zip(preds, ys)):\n",
    "        res[i] = num_cycles_left(p, y, rule, data_metadata)\n",
    "    return np.nanmean(res)\n",
    "\n",
    "def too_early(stop, ys, threshold):\n",
    "    # whether the engine is taken out at a stage earlier than it should have been\n",
    "    if stop+1 >= len(ys): return False \n",
    "    return ys[stop + 1] >= threshold # next sample could also have been included\n",
    "\n",
    "def too_late(stop, ys, threshold=0):\n",
    "    if stop >= len(ys):\n",
    "        return ys[-1] <= threshold\n",
    "    return ys[stop] <= threshold\n",
    "\n",
    "def too_early_rate(model_path, rule, threshold, errors=None):\n",
    "    preds, ys = load_p_y(model_path, errors) \n",
    "    num_early = 0\n",
    "    for p, y in zip(preds, ys):\n",
    "        stop = rule(p)\n",
    "        num_early += int(too_early(stop, y, threshold))\n",
    "    return num_early / len(preds)\n",
    "\n",
    "def too_late_rate(model_path, rule, threshold=0, errors=None):\n",
    "    preds, ys = load_p_y(model_path, errors) \n",
    "    num_late = 0\n",
    "    for p, y in zip(preds, ys):\n",
    "        stop = rule(p)\n",
    "        num_late += int(too_late(stop, y, threshold))\n",
    "    return num_late / len(preds)\n",
    "\n",
    "def load_errors(attack):\n",
    "    \"\"\" \n",
    "    take a folder \"attack\", containing examples, and return a list of (engine, time_idx, adv_lbl)\n",
    "    \"\"\"\n",
    "    examples = Path(attack) / 'examples'\n",
    "    ids_times = torch.load(examples /'ids_times.pt')\n",
    "    adv_lbl = torch.load(examples / 'adv_lbl.pt')\n",
    "    return [(i[0], i[1], l) for i, l in zip(ids_times, adv_lbl)]\n",
    "\n",
    "def cost_of_model(model_path, rule='matrix', thresholds=[0, 4], C1=32.5, C2=4, C3=11.1, mean_rul=.5, cm=None, errors=None):\n",
    "    \"\"\"\n",
    "    Find the cost of using one model depending on some decision rule and the model's performance\n",
    "    \"\"\"\n",
    "    if rule == 'matrix': \n",
    "        if cm is None:\n",
    "            with open(model_path / 'stats.json') as f:\n",
    "                stats = json.load(f)\n",
    "            try: cm = stats['cm']\n",
    "            except KeyError: cm = stats['confusion_matrix']\n",
    "        return cost_of_matrix(cm, thresholds[1])\n",
    "    else:\n",
    "        with open(model_path / 'data_metadata.json') as f:\n",
    "            data_metadata = json.load(f)\n",
    "        cycles_left = mean_num_cycles_left(model_path, rule, errors, data_metadata)\n",
    "        # print(cycles_left)\n",
    "        p1 = too_early_rate(model_path, rule, thresholds[-1], errors) # underestimation of remaining life\n",
    "        p2 = too_late_rate(model_path, rule, thresholds[0], errors) # overestimation of remaining life\n",
    "        # print(f'too early {p1=}, too late {p2=}')\n",
    "        cost = cycles_left * (C2 + C3/14) + p1 * (C2 + C3/14) + p2 * (C1 + C3) \n",
    "        return cost # / c_baseline\n",
    "\n",
    "def cost_of_sequence_attacks(model_path, rule, thresholds=[0, 3], C1=32.5, C2=4, C3=11.1, mean_rul=.5, attacks=['untargeted'], perturbation_sizes=[0.]):\n",
    "    \"\"\"\n",
    "    For a given model and attack parameters, find the cost in the different attack cases\n",
    "    \"\"\"\n",
    "    results = {a: [] for a in attacks}\n",
    "    for attack in attacks:\n",
    "        for eps in perturbation_sizes:\n",
    "            if eps > 1e-4:\n",
    "                errors = load_errors(model_path / adv_dir / f'attack_type=\\'{attack}\\'_perturbation_size={eps}')\n",
    "            else:\n",
    "                errors = None \n",
    "            cost = cost_of_model(model_path, thresholds=thresholds, C1=C1, C2=C2, C3=C3, mean_rul=mean_rul, errors=errors, rule=rule)\n",
    "            results[attack].append(cost)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "C1=32.5\n",
    "C2=4\n",
    "C3=11.1\n",
    "\n",
    "baseline_rates = [.15, .2, .25, .3, .35]\n",
    "baseline_rates = [r*(C2 + C3/14) for r in baseline_rates]\n",
    "thresholds = [0, 3]\n",
    "\n",
    "def plot_sequence_cost(which, duration, rule, attack='untargeted', perturbation_sizes=perturbation_sizes):\n",
    "    path = Path(f'{prefix}/{which=}_{duration=}')\n",
    "    model = choose_model(path, model='best')\n",
    "    # print(which, duration)\n",
    "    results = cost_of_sequence_attacks(model, rule, attacks=[attack], thresholds=thresholds, perturbation_sizes=perturbation_sizes, C1=C1, C2=C2, C3=C3)[attack]\n",
    "    return results\n",
    "\n",
    "def rule(preds):\n",
    "    \"\"\"\n",
    "    find the last time point in preds which we include\n",
    "    \"\"\"\n",
    "    for i, p in enumerate(preds):\n",
    "        if p < 2 or (i > 1 and p < 3 and preds[i-1] < 3):\n",
    "            return i \n",
    "    return len(preds)\n",
    "\n",
    "fig, axs = plt.subplots(1, len(whichs), figsize=(10, 5))\n",
    "for i, which in enumerate(whichs):\n",
    "    ax = axs[i]\n",
    "    for duration in durations:\n",
    "        res = plot_sequence_cost(which, duration, rule)\n",
    "        ax.plot(perturbation_sizes, res, label=f'Duration = {duration}')\n",
    "    ax.legend()\n",
    "    ax.set_title(f'Cost using dataset {which}')\n",
    "    ax.hlines(baseline_rates, min(perturbation_sizes), max(perturbation_sizes), linestyle='--') # color=['lightcoral', 'indianred', 'brown'], \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_statistics(stat='acc', critical_class=3, attacks=['targeted', 'untargeted', 'targeted_increase', 'targeted_decrease']):\n",
    "    def plot_accs(which, attack, filename=None):\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        ax.set_title(f'{attack}_{which=}')\n",
    "        for duration in durations:\n",
    "            key = f'{which=}_{duration=}'\n",
    "            if stat == 'acc':\n",
    "                y = [adv_accs[key][attack][str(s)]['acc'] for s in perturbation_sizes]\n",
    "            elif stat == 'cost':\n",
    "                y =[\n",
    "                    cost_of_matrix(adv_accs[key][attack][str(s)]['cm'], critical_class) for s in perturbation_sizes\n",
    "                ]\n",
    "            ax.plot(x, y, label=key)\n",
    "            # ax.set_ylim(.5, 1)\n",
    "            ax.grid()\n",
    "            ax.set_xlabel('perturbation size')\n",
    "            ax.set_ylabel(stat)\n",
    "        ax.legend()\n",
    "        if filename is not None: \n",
    "            dir = Path('/'.join(filename.split('/')[:-1]))\n",
    "            dir.mkdir(exist_ok=True, parents=True)\n",
    "            fig.savefig(filename)\n",
    "        return fig, ax \n",
    "    # get accs\n",
    "    regular_accs = {}\n",
    "    adv_accs = {}\n",
    "    for which in whichs:\n",
    "        for duration in durations:\n",
    "            key = f'{which=}_{duration=}'\n",
    "            regular_accs[key] = get_stats_regular(which, duration, model='best')\n",
    "            adv_accs[key] = get_stats_attack(which, duration, model='best')\n",
    "\n",
    "    # plot targeted results, resulting in a plot per \"which\"\n",
    "    # x=perturbation_size, y=acc\n",
    "    # where we have one line for each duration\n",
    "    x = perturbation_sizes \n",
    "    for which in whichs:\n",
    "        for attack in attacks:\n",
    "            fig, ax = plot_accs(which, attack, filename=f'plots/{prefix}/{which=}_{duration=}_{attack=}_{stat=}.png')\n",
    "\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_statistics(stat='acc', attacks=attack_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_statistics(stat='cost', critical_class=2, attacks=attack_types) # old way of computing cost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a more visual idea of what these attacks are doing\n",
    "\n",
    "In the plots below, a star marks that we could perturb a model to predict this value. The regular predictions are crosses and the true values are circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out where we could introduce errors\n",
    "attack = 'untargeted'\n",
    "perturbation_size = perturbation_sizes[-2]\n",
    "which = 1 \n",
    "duration = 50\n",
    "chosen_model = choose_model(f'{prefix}/{which=}_{duration=}', 'best')\n",
    "examples = chosen_model / f'{adv_dir}/attack_type=\\'{attack}\\'_{perturbation_size=}/examples/'\n",
    "attack_ids = torch.load(examples / 'ids.pt')\n",
    "engines_times = torch.load(examples/'ids_times.pt')\n",
    "adv_lbl = torch.load(examples / 'adv_lbl.pt')\n",
    "engine_errors = {v.item(): [] for v in torch.unique(engines_times[:, 0])}\n",
    "for i, (e, t) in enumerate(engines_times):\n",
    "    engine_errors[e.item()].append((t.item(), adv_lbl[i].item()))\n",
    "print(engine_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(chosen_model /'preds_ys.json') as f:\n",
    "    preds_ys = json.load(f)\n",
    "\n",
    "for engine, vals in engine_errors.items():\n",
    "    time = [v[0] for v in vals]\n",
    "    cl = [v[1] for v in vals]\n",
    "    preds = preds_ys['preds'][engine]\n",
    "    ys = preds_ys['ys'][engine]\n",
    "    plt.plot(np.arange(len(preds)), ys, 'o')\n",
    "    plt.plot(np.arange(len(preds)), preds, 'x')\n",
    "    plt.plot(time, cl, '*')\n",
    "    plt.ylim((-.5, n_classes))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

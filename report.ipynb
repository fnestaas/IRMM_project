{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report on Adversarial Examples\n",
    "This notebook should \n",
    "1. Train new models with different parameters\n",
    "1. for each model, generate both a **targeted** and **untargeted** PGD attack\n",
    "1. Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from pathlib import Path \n",
    "from matplotlib import pyplot as plt \n",
    "import json \n",
    "\n",
    "prefix = 'experiments/'\n",
    "adv_dir = 'attacks/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train New Models\n",
    "Each with a specific set of parameters, including data parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_args(param):\n",
    "    \"\"\"\n",
    "    turn parameter dictionary into list of arguments\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for k, v in param.items():\n",
    "        out.append('--' + k)\n",
    "        out.append(str(v))\n",
    "    return out \n",
    "\n",
    "durations = [50, 100, 150]\n",
    "whichs = [1, 2, 3, 4]\n",
    "model_params = {\n",
    "    f'{prefix}{which=}_{duration=}': {'duration': duration, 'which': which} \n",
    "    for duration in durations for which in whichs\n",
    "}\n",
    "\n",
    "\n",
    "# create models\n",
    "for name, v in model_params.items():\n",
    "    subprocess.run(['python', 'lstm.py'] + make_args(v) + ['--target_directory', name])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Adversarial Examples\n",
    "Save the results with the model in the appropriate folder, both for targeted and untargeted attacks. \n",
    "\n",
    "Parameters of the attack:\n",
    "- Attack type (targeted or untargeted)\n",
    "- Perturbation size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each model, make a number of attacks \n",
    "# To that end, make a subfolder \"attacks\" for each of the models\n",
    "for name in model_params.keys():\n",
    "    attack_types = ['targeted', 'untargeted']\n",
    "    perturbation_sizes = [.01, .05, .1]\n",
    "\n",
    "    attack_params = {\n",
    "        f'{adv_dir}{attack_type=}_{perturbation_size=}/': {'attack_type': attack_type, 'perturbation_size': perturbation_size} \n",
    "        for attack_type in attack_types for perturbation_size in perturbation_sizes\n",
    "    }\n",
    "    for attack_name, v in attack_params.items():\n",
    "        subprocess.run(['python', 'attack.py'] + make_args(v) + ['--source_directory', name, '--target_directory', attack_name])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each model, plot the accuracy against perturbation size, both targeted and untargeted\n",
    "cwd = Path().cwd()\n",
    "model_name = 'max'\n",
    "for experiment in model_params.keys():\n",
    "    # get accuracy and adv accuracy\n",
    "    dir = cwd / experiment\n",
    "    if model_name == 'max':\n",
    "        model_name = max([str(i) for i in dir.iterdir()])\n",
    "    dir = dir / model_name\n",
    "    with open(str(dir / 'stats.json')) as f:\n",
    "        stats = json.load(f)\n",
    "    acc = stats['acc']\n",
    "    attack_dir = dir / 'attacks'\n",
    "    adv_accs = {'targeted': [], 'untargeted': []}\n",
    "    for attack in attack_dir.iterdir():\n",
    "        with open(str(attack / 'adv_stats.json')) as f:\n",
    "            adv_stats = json.load(f)\n",
    "        adv_acc = adv_stats['acc']\n",
    "        if 'untargeted' in str(attack):\n",
    "            adv_accs['untargeted'].append(adv_acc)\n",
    "        else:\n",
    "            adv_accs['targeted'].append(adv_acc)\n",
    "    \n",
    "    # make the plot\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax.plot(perturbation_sizes, [acc] * len(perturbation_sizes), label='regular')\n",
    "    ax.plot(perturbation_sizes, adv_accs['targeted'], label='targeted')\n",
    "    ax.plot(perturbation_sizes, adv_accs['untargeted'], label='untargeted')\n",
    "    ax.legend()\n",
    "    ax.set_title(experiment)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(str(dir / 'accuracies.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
